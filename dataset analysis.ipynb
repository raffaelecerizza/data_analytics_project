{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import dataset_utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEWS_DATASET_PATH = \"./dataset/Grocery_and_Gourmet_Food_5.json\"\n",
    "PRODUCTS_DATASET_PATH = \"./dataset/meta_Grocery_and_Gourmet_Food.json\"\n",
    "PREPROCESSED_DATASET_PATH = \"./dataset/dataset.csv\"\n",
    "PREPROCESSED_DATASET_REVIEWS_PATH = \"./dataset/dataset_prep_reviews.csv\"\n",
    "GENERAL_INFO_PATH = \"./dataset/general_info.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the dataset with the reviews.\n",
    "reviews_dataset = pd.read_json(REVIEWS_DATASET_PATH, lines=True)\n",
    "reviews_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the dataset of the products.\n",
    "products_dataset = pd.read_json(PRODUCTS_DATASET_PATH, lines=True)\n",
    "products_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print some dataset information before the preprocessing.\n",
    "reviewers = np.unique(reviews_dataset['reviewerID'].values)\n",
    "products = np.unique(reviews_dataset['asin'].values)\n",
    "print(\"Number of reviews: \", len(reviews_dataset))\n",
    "print(\"Number of reviewers: \", len(reviewers))\n",
    "print(\"Number of products: \", len(products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We preprocess the reviews dataset.\n",
    "reviews_dataset = dataset_utils.preprocess_reviews_dataset(reviews_dataset)\n",
    "reviews_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We merge the reviews datasets with the products dataset.\n",
    "dataset = dataset_utils.merge_reviews_and_products(reviews_dataset, products_dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(PREPROCESSED_DATASET_PATH, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print some dataset information after the preprocessing.\n",
    "reviewers = np.unique(dataset['reviewerID'].values)\n",
    "products = np.unique(dataset['asin'].values)\n",
    "print(\"Number of reviews: \", len(dataset))\n",
    "print(\"Number of reviewers: \", len(reviewers))\n",
    "print(\"Number of products: \", len(products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print the NaN values of the dataset.\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reload the dataset and remove NaN summaries.\n",
    "dataset = pd.read_csv(PREPROCESSED_DATASET_PATH)\n",
    "dataset.isna().sum()\n",
    "dataset = dataset.dropna(subset=['summary'], how='any')\n",
    "dataset.to_csv(PREPROCESSED_DATASET_PATH, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print statistics for the numeric values.\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We preprocess the reviews and save the new dataset.\n",
    "dataset = dataset_utils.preprocess_reviews(dataset)\n",
    "dataset.to_csv(PREPROCESSED_DATASET_REVIEWS_PATH, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(PREPROCESSED_DATASET_PATH)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print statistics for the numeric values.\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print the NaN values of the dataset.\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_summ = dataset[dataset['summary'] == \"NaN\"]\n",
    "nan_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_summ = dataset[dataset['summary'].isna()]\n",
    "nan_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print the percentages of NaN values of the dataset.\n",
    "dataset.isna().sum() / len(dataset) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print some dataset information after the preprocessing.\n",
    "reviewers = np.unique(dataset['reviewerID'].values)\n",
    "products = np.unique(dataset['asin'].values)\n",
    "print(\"Number of reviews: \", len(dataset))\n",
    "print(\"Number of reviewers: \", len(reviewers))\n",
    "print(\"Number of products: \", len(products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reviews from verified purchases.\n",
    "number_verified_purchases = len(dataset[dataset['verified'] == True])\n",
    "number_reviews = len(dataset)\n",
    "perc_verified_purchases = number_verified_purchases / number_reviews * 100\n",
    "print(f\"There are {number_verified_purchases} reviews from verified purchases out of {number_reviews} reviews.\")\n",
    "print(f\"Percentage of reviews from verified purchases: {perc_verified_purchases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create and save a dataframe for general information about the preprocessed dataset.\n",
    "number_products = len(np.unique(dataset['asin'].values))\n",
    "number_reviewers = len(np.unique(dataset['reviewerID'].values))\n",
    "average_rating = dataset.describe().loc['mean', 'rating']\n",
    "general_info_data = {\"Number of reviews\": [number_reviews], \n",
    "                     \"Number of products\": [number_products], \n",
    "                     \"Number of reviewers\": [number_reviewers], \n",
    "                     \"Percentage of verified purchases\": [perc_verified_purchases],\n",
    "                     \"Average rating\": [average_rating]}\n",
    "general_info = pd.DataFrame(general_info_data)\n",
    "general_info.to_csv(GENERAL_INFO_PATH, encoding='utf-8', index=False)\n",
    "general_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the distribution of ratings in the preprocessed dataset.\n",
    "dataset_utils.plot_ratings_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the distribution of opinions.\n",
    "dataset_utils.plot_opinions_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the distribution of reviews' length.\n",
    "dataset_utils.plot_reviews_length_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the distribution of summaries' length.\n",
    "dataset_utils.plot_summaries_length_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the distribution of reviews by their price.\n",
    "dataset_utils.plot_reviews_price_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the distribution of products by their price.\n",
    "dataset_utils.plot_products_price_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot an analysis of the relation between ratings and prices.\n",
    "dataset_utils.plot_rating_price_relation(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_purchases = dataset[dataset['verified'] == True]\n",
    "# We plot the distribution of ratings and opinions of verified purchases.\n",
    "dataset_utils.plot_ratings_distribution(verified_purchases, verified=True)\n",
    "dataset_utils.plot_opinions_distribution(verified_purchases, verified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the distribution of reviews for each year.\n",
    "dataset_utils.plot_reviews_year_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the top and bottom reviewers for number of reviews.\n",
    "dataset_utils.plot_reviewers(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the top and bottom products for number of reviews.\n",
    "dataset_utils.plot_products(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the average number of reviews per product.\n",
    "dataset_utils.compute_average_reviews_per_product(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the average number of reviews per reviewer.\n",
    "dataset_utils.compute_average_reviews_per_reviewer(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the distribution of the average rating per product.\n",
    "dataset_utils.plot_average_rating_per_product_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the top rated products by average rating.\n",
    "dataset_utils.plot_top_rated_products(dataset, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the distribution of the average rating per reviewer.\n",
    "dataset_utils.plot_average_rating_per_reviewer_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot relevant information over the years.\n",
    "dataset_utils.plot_information_over_time(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations between variables.\n",
    "dataset_utils.plot_correlations(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot words information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(PREPROCESSED_DATASET_REVIEWS_PATH)\n",
    "dataset['preprocessedReviewText'] = dataset['preprocessedReviewText'].fillna(\"\") \n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print and plot the most common words of the reviews.\n",
    "dataset_utils.plot_most_common_words(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_dataset = dataset[dataset['opinion'] == 'negative']\n",
    "# We print and plot the most common words of the negative reviews.\n",
    "dataset_utils.plot_most_common_words(negative_dataset, opinion=\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_dataset = dataset[dataset['opinion'] == 'neutral']\n",
    "# We print and plot the most common words of the neutral reviews.\n",
    "dataset_utils.plot_most_common_words(neutral_dataset, opinion=\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dataset = dataset[dataset['opinion'] == 'positive']\n",
    "# We print and plot the most common words of the positive reviews.\n",
    "dataset_utils.plot_most_common_words(positive_dataset, opinion=\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the most common words for all the opinions.\n",
    "dataset_utils.plot_intersection_most_common_words(negative_dataset, neutral_dataset, positive_dataset, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print the tokens that are present in a number of reviews that exceeds a threshold.\n",
    "dataset_utils.find_frequent_tokens_in_reviews(dataset, threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print the tokens that are present in a number of reviews that exceeds a threshold.\n",
    "dataset_utils.find_frequent_tokens_in_reviews(dataset, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
